{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Additional Functions with Keras\n",
    "\n",
    "- 3.1 모델 합치기 with CIFAR10\n",
    "- 3.2 데이터 증강\n",
    "- 3.3 Finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 모델 합치기 with CIFAR10\n",
    "\n",
    "convolution과 maxpooling layer로 구성된 feature extractor 모델과\n",
    "\n",
    "fully connected layer로 구성된 ANN classifier 모델을 따로 정의하고\n",
    "\n",
    "두 모델을 합쳐서 CNN 모델을 만듬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) 데이터셋 : CIFAR 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.utils as utils\n",
    "from tensorflow.keras import datasets\n",
    "\n",
    "# Dataset Load\n",
    "(X_train, Y_train), (X_test, Y_test) = datasets.cifar10.load_data()\n",
    "\n",
    "# Dataset Confirm\n",
    "print(X_train.shape, Y_train.shape)\n",
    "print('label : ',Y_train[0])\n",
    "plt.imshow(X_train[0])\n",
    "\n",
    "# Dataset Preprocessing\n",
    "X_train = X_train/255.0\n",
    "X_test = X_test/255.0\n",
    "Y_train = utils.to_categorical(Y_train)\n",
    "Y_test = utils.to_categorical(Y_test)\n",
    "\n",
    "print(X_train.shape, Y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Dense, Activation\n",
    "from tensorflow.keras.layers import Flatten, BatchNormalization, Dropout, ReLU\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_in = X_train.shape[1:]\n",
    "n_out = Y_train.shape[-1]\n",
    "\n",
    "def conv_maxpool_layers(n_in):\n",
    "    # Coding Time\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, kernel_size=(3,3), padding='same', activation='relu', input_shape=(n_in)))\n",
    "    model.add(Conv2D(32, kernel_size=(3,3), padding='same', strides=(2,2), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Flatten())\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def fc_layers(n_out):\n",
    "    # Coding Time\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=128, input_shape = (2048,), activation='relu'))\n",
    "    model.add(Dense(units=n_out, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def CNN_sum(n_in, n_out):\n",
    "    \n",
    "    # Coding Time\n",
    "    \n",
    "    #각 부분 모델\n",
    "    feature_extractor=conv_maxpool_layers(n_in)\n",
    "    feature_extractor.trainable=True\n",
    "    ann_classifier=fc_layers(n_out)\n",
    "    ann_classifier.trainable=True\n",
    "    \n",
    "    #두 모델을 합쳐 새로운 모델 정의(Functional Style)\n",
    "    x= Input(shape=n_in)\n",
    "    feature = feature_extractor(x)\n",
    "    y= ann_classifier(feature)\n",
    "    model = Model(inputs = x, outputs = y)\n",
    "    \n",
    "    '''\n",
    "    Sequential Style\n",
    "    model = Sequential()\n",
    "    model.add(feature_extractor)\n",
    "    model.add(ann_classifier)\n",
    "    '''\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN_sum(n_in, n_out)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3-4) 모델의 학습과정 설정 / 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "earlystopper = EarlyStopping(monitor='val_accuracy', patience=7, verbose=1, mode='auto', restore_best_weights=True)\n",
    "history = model.fit(X_train, Y_train, batch_size=128, epochs=50, validation_split=0.2, callbacks = [earlystopper])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (5) 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_and_accuracy = model.evaluate(X_test, Y_test, batch_size=128)\n",
    "print('loss : %.4f, accruracy : %.4f'%(loss_and_accuracy[0],loss_and_accuracy[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Image data augmentation\n",
    "케라스에서는 ImageDataGenerate 함수로 Data augmentation 기능을  제공\n",
    "\n",
    "https://keras.io/preprocessing/image/#imagedatagenerator-class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1)-2 데이터 증강 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center = False,\n",
    "    samplewise_center = False,\n",
    "    featurewise_std_normalization = False,\n",
    "    samplewise_std_normalization = False,\n",
    "    zca_whitening = False,\n",
    "    rotation_range = 2, # 회전\n",
    "    zoom_range = 0.1, # 확대 축소\n",
    "    width_shift_range = 0.1, # 수평 이동\n",
    "    height_shift_range = 0.1, # 수직 이동\n",
    "    horizontal_flip = True, # 수평 반전|\n",
    "    vertical_flip = False # 수직 반전\n",
    ")\n",
    "\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### (3-4) 모델의 학습과정 설정 / 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = CNN_sum(n_in, n_out)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "earlystopper = EarlyStopping(monitor='val_accuracy', patience=7, verbose=1, mode='auto', restore_best_weights=True)\n",
    "# Coding Time\n",
    "model.fit(datagen.flow(X_train[:-10000], Y_train[:-10000], batch_size= 128),\n",
    "         epochs = 50, validation_data=(X_train[-10000:],Y_train[-10000:]), verbose = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_and_accuracy = model.evaluate(X_test, Y_test, batch_size=128)\n",
    "print('loss : %.4f, accruracy : %.4f'%(loss_and_accuracy[0],loss_and_accuracy[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Transfer learning\n",
    "Transfer learning을 통해 현재 쓰이고 있는 네트워크를 가져와 학습하는 방법을 배워본다(Classifier만 / Entire)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) 모델링1 : Classifier learning\n",
    "    \n",
    "사용가능 네트워크 :\n",
    "https://keras.io/api/applications/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coding Time\n",
    "base_model = VGG16(weights='imagenet', input_shape=(32,32,3), include_top=False)\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Feature Extroactor from VGG16\n",
    "x = base_model.output\n",
    "# 1,1,512\n",
    "# Add Classifier\n",
    "x = Flatten()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "predictions = Dense(Y_train.shape[1], activation='softmax')(x) #Y_train.shape[1] :10 \n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first: train only the top layers (which were randomly initialized)\n",
    "for layer in base_model.layers: # Frosen 하기\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) 모델의 학습과정 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4) 모델 학습시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "earlystopper = EarlyStopping(monitor='val_accuracy', patience=7, verbose=1, mode='auto', restore_best_weights=True)\n",
    "history = model.fit(X_train, Y_train, batch_size=128, epochs=50, validation_split=0.2, callbacks = [earlystopper])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, loss_ax = plt.subplots()\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(history.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(history.history['val_loss'], 'r', label='val loss')\n",
    "\n",
    "acc_ax.plot(history.history['accuracy'], 'b', label='train acc')\n",
    "acc_ax.plot(history.history['val_accuracy'], 'g', label='val acc')\n",
    "\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "acc_ax.set_ylabel('accuray')\n",
    "\n",
    "loss_ax.legend(loc='upper left')\n",
    "acc_ax.legend(loc='lower left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (5) 모델 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss_and_accuracy = model.evaluate(X_test, Y_test, batch_size=128)\n",
    "print('loss : %.4f, accruracy : %.4f'%(loss_and_accuracy[0],loss_and_accuracy[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) 모델링1 : Entire\n",
    "    \n",
    "사용가능 네트워크 :\n",
    "https://keras.io/api/applications/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Feature Extroactor from VGG16\n",
    "x = base_model.output\n",
    "\n",
    "# Add Classifier\n",
    "x = Flatten()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "predictions = Dense(Y_train.shape[1], activation='softmax')(x) #Y_train.shape[1] :10 \n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first: train the all layers (which were randomly initialized)\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) 모델의 학습과정 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4) 모델 학습시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "earlystopper = EarlyStopping(monitor='val_accuracy', patience=7, verbose=1, mode='auto', restore_best_weights=True)\n",
    "history = model.fit(X_train, Y_train, batch_size=128, epochs=50, validation_split=0.2, callbacks = [earlystopper])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, loss_ax = plt.subplots()\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(history.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(history.history['val_loss'], 'r', label='val loss')\n",
    "\n",
    "acc_ax.plot(history.history['accuracy'], 'b', label='train acc')\n",
    "acc_ax.plot(history.history['val_accuracy'], 'g', label='val acc')\n",
    "\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "acc_ax.set_ylabel('accuray')\n",
    "\n",
    "loss_ax.legend(loc='upper left')\n",
    "acc_ax.legend(loc='lower left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (5) 모델 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_and_accuracy = model.evaluate(X_test, Y_test, batch_size=128)\n",
    "print('loss : %.4f, accruracy : %.4f'%(loss_and_accuracy[0],loss_and_accuracy[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.4 Keras MNIST - 모델의 성능을 직접 높혀보자\n",
    " - CNN의 구조를 바꾸어 나만의 모델을 만들어보자\n",
    " - 목표 정확도: 99.5% 만들기\n",
    " - 바꿀 수 있는 하이퍼 파라미터: Learning Rate, Batch size, Epochs, Optimizer, Activation Function, 모델 레이어 구조, BN, DO, DA, Fine Tuning 등"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) 데이터셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'datasets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Coding Time\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m (x_train, y_train),(x_test, y_test) \u001b[38;5;241m=\u001b[39m \u001b[43mdatasets\u001b[49m\u001b[38;5;241m.\u001b[39mmnist\u001b[38;5;241m.\u001b[39mload_data()\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(x_train\u001b[38;5;241m.\u001b[39mshape, y_train\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'datasets' is not defined"
     ]
    }
   ],
   "source": [
    "# Coding Time\n",
    "(x_train, y_train),(x_test, y_test) = datasets.mnist.load_data()\n",
    "print(x_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) Keras 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center = False,\n",
    "    samplewise_center = False,\n",
    "    featurewise_std_normalization = False,\n",
    "    samplewise_std_normalization = False,\n",
    "    zca_whitening = False,\n",
    "    rotation_range = 2, # 회전\n",
    "    zoom_range = 0.1, # 확대 축소\n",
    "    width_shift_range = 0.1, # 수평 이동\n",
    "    height_shift_range = 0.1, # 수직 이동\n",
    "    horizontal_flip = True, # 수평 반전|\n",
    "    vertical_flip = False # 수직 반전\n",
    ")\n",
    "\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_in = X_train.shape[1:]\n",
    "n_out = Y_train.shape[-1]\n",
    "\n",
    "def conv_maxpool_layers(n_in):\n",
    "    # Coding Time\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, kernel_size=3, padding='same', activation='relu', input_shape=(n_in)))\n",
    "    model.add(Conv2D(32, kernel_size=3, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Flatten())\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def fc_layers(n_out):\n",
    "    # Coding Time\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=14*14, input_shape = (14*14,1), activation='relu'))\n",
    "    model.add(Dense(units=n_out, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def CNN_sum(n_in, n_out):\n",
    "    \n",
    "    # Coding Time\n",
    "    \n",
    "    #각 부분 모델\n",
    "    feature_extractor=conv_maxpool_layers(n_in)\n",
    "    feature_extractor.trainable=True\n",
    "    ann_classifier=fc_layers(n_out)\n",
    "    ann_classifier.trainable=True\n",
    "    \n",
    "    #두 모델을 합쳐 새로운 모델 정의(Functional Style)\n",
    "    x= Input(shape=n_in)\n",
    "    feature = feature_extractor(x)\n",
    "    y= ann_classifier(feature)\n",
    "    model = Model(inputs = x, outputs = y)\n",
    "    \n",
    "    '''\n",
    "    Sequential Style\n",
    "    model = Sequential()\n",
    "    model.add(feature_extractor)\n",
    "    model.add(ann_classifier)\n",
    "    '''\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN_sum(n_in, n_out)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystopper = EarlyStopping(monitor='val_accuracy', patience=7, verbose=1, mode='auto', restore_best_weights=True)\n",
    "history = model.fit(x_train, y_train, batch_size=128, epochs=50, validation_split=0.2, callbacks = [earlystopper])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_and_accuracy = model.evaluate(x_test, y_test, batch_size=128)\n",
    "print('loss : %.4f, accruracy : %.4f'%(loss_and_accuracy[0],loss_and_accuracy[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mldl",
   "language": "python",
   "name": "mldl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
